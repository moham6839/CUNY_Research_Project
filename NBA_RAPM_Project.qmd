---
title: "Analyzing NBA Player Performance using Regularized Adjusted Plus/Minus"
author: "Mohamed Hassan El-Serafi"
format: pdf
toc: true
toc-title: Table of Contents
toc-location: left
editor: visual
bibliography: references.bib
---

## Introduction

Organizationsn in the National Basketball Association have attempted to evaluate player performance using various methods. Scouts attend basketball games to assess a player’s strengths and weaknesses. Video coordinators utilize film from previous games to analyze how their own respective team or opposing team’s players performed, building reports intended to highlight areas of strengths and weaknesses, and strategize how best to help improve the performance of their own players or approach playing against an opposing team’s players. Traditional basketball statistics such as points, rebounds, assists, turnovers, field goal and 3-point percentages are commonly used as metrics to evaluate a player’s on-court productivity. While those evaluation methods are still applied, advanced statistics has become increasingly utilized for assessing a player’s performance. Advanced statistics such as Player Efficiency Rating (PER) and Net Rating are two common metrics used to gauge a player’s effectiveness in impacting a basketball game. PER is a rating of a player's per-minute productivity, adding up all a player’s up all a player's positive accomplishments, subtracting their negative accomplishments, and returning a per-minute rating of a player's performance [@noauthor_calculating_nodate]. Net rating calculates the offensive rating (100 \* (Points)/(Possession)) minus the defensive rating (100\*(Opponent Points)/(Possession)), indicating how much better or worse the team performs with the player on the court [@fijal_nba_nodate]. These ratings are typically calculated on a per-possession basis.

Despite being two popular evaluation metrics, the Plus/Minus stat has become widely used by player evaluators to help inform their decision-making on roster construction and game strategy. It indicates how many points a team gained or lost relative to the opponent when a player was on the floor [@deckard_demystifying_2024]. For example, if Player A comes in the game and his team is up by 10, but they’re tied when he exits the game, his plus/minus for that stretch will be -10. While this stat may give insight on how a player positively or negatively impacts their team’s performance, there are other variables that taken in its raw form does not account for, namely the fact that there are four other offensive players and five defensive players on the court that could have more of an impact on the game, whether the player is playing at home or on the road, and whether the minutes a player plays are important based on the time and score of the game. This raises some questions: Does a player with an unexpectedly high Plus/Minus benefit from circumstances, or is he doing something that creates value that we might not be seeing? Is a player with an unexpectedly low Plus/Minus not as good as we thought or is he just in an unfortunate situation [@antle_regularized_nodate]?

To address these circumstances, Dan Rosenbaum helped develop the Adjusted Plus/Minus (APM) stat, which reflects the impact of a player on his team’s scoring margin, factoring the other nine players on the court, the length of time a player is in the game, and the score at the start and end of the player’s time on the court [@noauthor_adjusted_2017]. In other words, it estimates player variables which produce the smallest difference between the expected margin and the actual margin in the matchups. Although this metric comes close to an unbiased measure of a player’s effectiveness, there are conflicts within the regression model. There is high variance, which indicates that the metric is capturing noise in the data and is prone to overfitting. This can lead to drastic variations of a player’s adjusted plus/minus value from one season to the next. Additionally, APM is susceptible to multicollinearity due to how players can be used in pairs and/or trios within 5-player lineups.

Due to the statistical flaws of APM, applying a regularization method to the model was developed by Joseph Sill. The purpose for using a regularization method is its ability to handle multicollinearity and prevent overfitting by shrinking coefficients towards zero[@murel2023].

## Literature Review

To address these shortcomings, Regularized Adjusted Plus/Minus was created. This metric applies a Ridge regression model, reducing the standard errors from APM, correcting for multicollinearity and addressing overfitting in the training data. In one paper authored by Joseph Sill, a Bayesian technique is used with Ridge regression as an enhancement in which the data is combined with prior knowledge regarding reasonable ranges for the parameters to produce more accurate models [@sill_improved_nodate].

The concept of RAPM was originally designed by Joseph Sill. Sill used data of complete seasons from the 2006-07 and 2007-08 and part of the 2008-09 season as his training data to predict his test set, which are the last two months of the ’08-’09 season (March and April). Additionally, a lambda value is used as a penalty to draw the coefficients close to zero, with a value of 2000 used for 1 year of data and 3000 for three years of data. Sill uses Root Mean-Squared Error (RMSE) of predicted vs. actual margin to measure the accuracy of the model, and cross-validation to determine the optimal minutes cutoff and weightings of past years for the standard APM linear regression technique. In Sill’s analysis, he uses data from the 2006-07 season through February of the 2008-09 season as his training set, with March and April of the 2008-09 season as his test set. Separately, Sill also uses only the 2008-09 season as his dataset, with data through February 2009 as his training set. He explains that the Adjusted R-squared was lower and Root Mean Squared Error (RMSE) was higher when using only 1 season of data compared to using three seasons of data.

As an alternative to using RAPM, Damoulaki, Ntzoufras, and Pelechrinis developed a different method called weighted expected points (wEPTS) [@damoulaki_lasso_2025]. According to the authors, the new
evaluation metric is based on the expected points per possession (EPTS) and its extended version, the weighted expected points (wEPTS). The latter measurement takes into consideration the proportion of possessions that each player participates in his team. It is derived as the points expected to be scored by the team over all games under the simplifed scenario that all other players on court belong to the reference group with zero-lasso RAPM measures. In addition to using ridge and lasso regression models, the authors applied binary and multinomial logistic regression models. The binary logistic model Their thinking is that the multinomial model is more suitable for modelling the points per possession and for producing player evaluation metrics since the obtained wEPTS evaluation index is found to be superior according to selected external validation criteria. The authors state that the metric partially solves the problem related to the overestimation of the performance of low-time players. The binary classifcation model was applied, predicting the outcome of scoring versus not scoring. Regularized logistic
regression was implemented, achieving an accuracy of approximately 55%. However, this approach neglected the actual number of points scored on each possession. Despite this, the authors discovered a linear relationship between the ratings generated from the ridge binomial model and ridge normal RAPMs. As a result, they converted normal RAPMs into logistic regression RAPMs, transforming the normal RAPM scores into a framework more appropriate for the binary outcome (scoring vs. not scoring), increasing interpretability of standard RAPM player performance metrics. The authors then applied a multinomial model to the number of points per possession, accounting for how many points can be scored during a possession (1, 2 or 3+).

## Methodology

For this analysis, I will explore the Regularized Adjusted Plus/Minus metric using play-by-play data for the past four completed NBA seasons: 2020-21 through 2023-24. Since a player’s performance may vary from one season to the next, the data compiles all four seasons, creating one large dataset. The data will be collected using an R package called hoopR. The process for extracting the data and implementing the models were derived from Ron Yurko and Quang Nguyen [@yurko]. The input variables are the players, with the margin (defined as: (home_points - away_points) / n_pos \* 100), being the target variable. There are a couple of options available to account for players that do not play a lot of minutes. Damoulaki, Ntzoufras, and Pelechrinis discuss the concept of Low-Time Players (LTP), defined as players who participate for less than a threshold of minutes per game[@damoulaki_lasso_2025]. While the authors implemented a minimum of at least 200 minutes played, Sill's methodology of using a cross-validation method is applied to determine the adequate minutes threshold for each player. The purpose of applying a type of threshold for minutes played is to account for the skewness in the amount of minutes players play in games. There are a disproportionate amount of players who don't play a lot of minutes. This is understandable, as there are only 5 players allowed to play on the court per team, with each team carrying 12-15 players at a time. The distribution of minutes played in this dataset illustrates this:

![](images/player_total_minutes.png)

The regression models adapted for this analysis are derived from methods applied by Sill and Damoulaki et al. While Sill applied a Ridge regression and Lasso regressions are regularization methods, I will use each technique on the dataset. Two additional regression techniques are to the dataset: Elastic Net and Bayesian. The purpose for using Elastic Net regression is its use of both Ridge and Lasso techniques, combining their penalty terms and learning from their shortcomings to improve regularization of statistical methods [@noauthor_elastic_nodate]. From previous analyses of RAPM, the authors have not applied an Elastic Net regression method on play-by-play data, and comparing its results to Ridge and Lasso could help give us a better understanding of each method’s strengths and limitations. The purpose for using Bayesian regression is its ability to incorporate prior knowledge of the data. While using Bayesian may not be suitable due to the large size of the dataset, it's simply used to assess its results with the other models.

The two main metrics I used to assess each model were Root Mean Squared Error (RMSE) and Adjusted R-squared. These metrics were used by Sill to compare the different ridge regression models he used

## References
